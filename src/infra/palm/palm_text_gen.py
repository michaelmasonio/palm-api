from typing import Dict, List
import google.generativeai as palm
from google.api_core import retry

from src.infra.palm.calculator import calculator
from src.infra.palm import palm_config as palm_config
from src.infra.palm import palm_embed as palm_embed

cfg = palm_config.load_config()
api_key = cfg["api_key"]

palm.configure(api_key=api_key)


@retry.Retry()
def generate_text(*args, **kwargs):
    return palm.generate_text(*args, **kwargs)


def text_generation(prompt):
    """
    Generates text based on a given prompt.

    Args:
        prompt (str): The input prompt for text generation.

    Returns:
        str: The generated text based on the input prompt.
    """
    models = [m for m in palm.list_models() if "generateText" in m.supported_generation_methods]
    model = models[0].name

    completion = palm.generate_text(model=model, prompt=prompt, temperature=0, max_output_tokens=800)

    return completion.result


def generate_candidates(prompt: str) -> str:
    """
    Generates a list of candidate completions for a given prompt.
    
    Args:
        prompt (str): The input prompt for generating completions.
        
    Returns:
        str: The completion generated by the model.
    """
    models = [m for m in palm.list_models() if "generateText" in m.supported_generation_methods]
    model = models[0].name
    
    completion = palm.generate_text(
        model=model,
        prompt=prompt,
        temperature=1,
        max_output_tokens=800,
        candidate_count=8,
    )

    return completion

def generate_close_to(question: str ) -> str:
    prompt = f"Please provide a similar but different statement for embeddings: {question}"
    models = [
        m
        for m in palm.list_models()
        if "generateText" in m.supported_generation_methods
    ]
    model = models[0].name

    completion = palm.generate_text(
        model=model,
        prompt=prompt,
        temperature=1,
        # The maximum length of the response
        max_output_tokens=800,
        candidate_count=1,
    )

    return completion

def generate_far_from(question: str) -> str:
    """
    Generates a text completion based on a given question.

    Args:
        question (str): The question to provide a dissimilar statement for.

    Returns:
        str: The generated text completion.
    """
    prompt = f"Please provide a dissimilar statement for embeddings: {question}"
    
    models = [m for m in palm.list_models() if "generateText" in m.supported_generation_methods]
    model = models[0].name
    
    completion = palm.generate_text(
        model=model,
        prompt=prompt,
        temperature=1,
        max_output_tokens=800,
        candidate_count=1,
    )
    
    return completion

def filter_candidates(question: str, candidates: List[Dict[str, str]]) -> List[Dict[str, str]]:
    # Generate close-to and far-from statements
    close_to = generate_close_to(question)
    far_from = generate_far_from(question)
    
    # Create embeddings for the question and candidates
    question_embed = palm_embed.create_embedding(x=question, close_to_x=close_to.result, different_from_x=far_from.result, model="models/embedding-gecko-001")
    candidate_embeds = []
    for candidate in candidates:
        candidate_close_to = generate_close_to(candidate["output"])
        candidate_far_from = generate_far_from(candidate["output"])
        candidate_embed = palm_embed.create_embedding(x=candidate["output"], close_to_x=candidate_close_to.result, different_from_x=candidate_far_from.result, model="models/embedding-gecko-001")
        candidate_embeds.append(candidate_embed)
    
    # Filter out candidates that are more similar than different
    filtered_candidates = []
    for i, embed in enumerate(candidate_embeds):
        similar = abs(question_embed[0] - embed[0])
        different = abs(question_embed[1] - embed[1])
        if similar < different:
            continue
        filtered_candidates.append(candidates[i])
    
    return filtered_candidates


# def text_gen_with_external_function(prompt):
#     models = [
#         m
#         for m in palm.list_models()
#         if "generateText" in m.supported_generation_methods
#     ]
#     model = models[0].name

#     completion = generate_text(
#         model=model,
#         prompt=prompt,
#         stop_sequences=["</calc>"],
#         # The maximum length of the response
#         max_output_tokens=800,
#         candidate_count=1,
#     )

#     result = completion.result
#     return result


# def solve(question, calc_prompt_template, answer):
#     """
#     Solves a question using a prompt template and an answer.

#     Args:
#         question (str): The question to be solved.
#         calc_prompt_template (str): The template for the calculation prompt.
#         answer: The expected answer to the question.

#     Returns:
#         bool: True if the question is successfully solved, False otherwise.
#     """
#     models = [
#         m
#         for m in palm.list_models()
#         if "generateText" in m.supported_generation_methods
#     ]
#     model = models[0].name

#     results = []

#     for n in range(11):
#         prompt = calc_prompt_template.format(question=question)

#         prompt += " ".join(results)

#         completion = generate_text(
#             model=model,
#             prompt=prompt,
#             stop_sequences=["</calc>"],
#             # The maximum length of the response
#             max_output_tokens=800,
#         )

#         result = completion.result
#         if not result:
#             break

#         if "<calc>" in result:
#             result = calculator.calculator(result)

#         results.append(result)
#         print("-" * 40)
#         print(result)
#         if str(answer) in result:
#             break
#         if "<calc>" not in result:
#             break

#     is_good = any(str(answer) in r for r in results)

#     print("*" * 100)
#     if is_good:
#         print("Success!")
#     else:
#         print("Failure!")
#     print("*" * 100)

#     return is_good


if __name__ == "__main__":
    generate_candidates("What is the color of saturn's rings?")


#     prompt = """
# You are an expert at solving word problems.

# Solve the following problem:

# I have three houses, each with three cats.
# each cat owns 4 mittens, and a hat. Each mitten was
# knit from 7m of yarn, each hat from 4m.
# How much yarn was needed to make all the items?

# Think about it step by step, and show your work.
# """

#     question = """
# I have 77 houses, each with 31 cats.
# Each cat owns 14 mittens, and 6 hats.
# Each mitten was knit from 141m of yarn, each hat from 55m.
# How much yarn was needed to make all the items?
# """

#     calc_prompt_template = """
# You are an expert at solving word probles. Here's a question:

# {question}

# -------------------

# When solving this problem, use the calculator for any arithmetic.

# To use the calculator, put an expression between <calc></calc> tags.
# The answer will be printed after the </calc> tag.

# For example: 2 houses  * 8 cats/house = <calc>2 * 8</calc> = 16 cats

# -------------------

# Work throught it step by step, and show your work.
# One step per line.

# The Answer is:
# """

#     # print(text_generation(prompt))
#     # calc_prompt_template = calc_prompt_template.format(question=question)
#     # print(text_gen_with_external_function(calc_prompt_template))

#     answer = 5499648
#     solve(question, calc_prompt_template, answer)
